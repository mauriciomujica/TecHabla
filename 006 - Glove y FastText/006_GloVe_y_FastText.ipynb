{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cuaderno Clase PLN - GloVe y FastText\n",
        "\n",
        "**Objetivos:**\n",
        "*   Conocer enfoques alternativos a Word2Vec: GloVe (conteos globales) y FastText (subpalabras).\n",
        "*   Entender la ventaja clave de FastText para manejar palabras fuera de vocabulario (OOV - Out Of Vocabulary).\n",
        "*   Cargar y usar vectores FastText pre-entrenados.\n",
        "*   Comparar resultados y capacidades (especialmente OOV) con Word2Vec.\n",
        "*   Reflexionar sobre cómo evaluar la calidad de los embeddings y detectar sesgos.\n",
        "\n",
        "**Agenda:**\n",
        "1.  Instalaciones e Importaciones\n",
        "2.  Repaso Rápido: Word2Vec y sus limitaciones (OOV)\n",
        "3.  GloVe: Vectores Globales desde Co-ocurrencias\n",
        "4.  FastText: El Poder de las Subpalabras (¡Adiós OOV!)\n",
        "5.  Cargando Vectores FastText Pre-entrenados\n",
        "6.  Explorando FastText: Similitud, Analogías y ¡OOV!\n",
        "7.  Comparativa: Word2Vec vs FastText (foco en OOV)\n",
        "8.  Micro-Laboratorio (Ejercicio Práctico)\n",
        "9.  Brainstorming: Evaluación y Detección de Sesgos"
      ],
      "metadata": {
        "id": "Rzh9Sg9UeB_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Instalaciones e Importaciones"
      ],
      "metadata": {
        "id": "CpBrBQ7-ejz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Necesitamos gensim principalmente\n",
        "!pip install gensim > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG4_rcP3eXrs",
        "outputId": "cd611375-8a4e-4d66-f86e-053089c31e7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall gensim -y # Remove the existing gensim installation\n",
        "!pip install gensim # Reinstall gensim to align with the NumPy version\n",
        "# Restart the kernel to ensure the changes take effect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "L56qQY6vevNr",
        "outputId": "5c2cd775-bd58-444b-adcd-1f72531be27f",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping gensim as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "095193f67cec4bef8e55ad777889b731"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwqWN5fAeBAl",
        "outputId": "e5061553-8840-499e-ec9a-b7859e9bbd0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Librerías importadas.\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.models import KeyedVectors, FastText # Ahora importamos FastText también\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Librerías importadas.\")\n",
        "\n",
        "# **Importante:** Para este cuaderno, idealmente necesitaremos:\n",
        "# 1. El modelo Word2Vec cargado previamente (para comparar).\n",
        "# 2. Un modelo FastText pre-entrenado para español (¡necesitamos descargarlo!)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20Y4SacYEEzd",
        "outputId": "89ddf304-d234-416a-dba0-c19f8e4e0582"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_fasttext = '/content/drive/MyDrive/glove_fasttext/wiki.es.bin'"
      ],
      "metadata": {
        "id": "_x3-luubmFb2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intentar cargar el modelo FastText\n",
        "try:\n",
        "    print(\"Cargando vectores FastText (.bin)... (¡Esto puede tardar MUCHO tiempo y consumir RAM!)\")\n",
        "    # Usamos FastText.load_fasttext_format para cargar modelos .bin de FastText\n",
        "    fasttext_model = gensim.models.fasttext.load_facebook_model(path_to_fasttext)\n",
        "    # Los vectores están dentro del atributo .wv (como en Word2Vec cargado con KeyedVectors)\n",
        "    fasttext_vectors = fasttext_model.wv\n",
        "    print(f\"¡Vectores FastText cargados! Vocabulario (estimado): {len(fasttext_vectors.index_to_key)} palabras. Dimensión: {fasttext_vectors.vector_size}\")\n",
        "    # Nota: El tamaño del vocabulario explícito puede ser menor en .bin, pero puede generar para OOV.\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: No se encontró el archivo FastText en la ruta '{path_to_fasttext}'.\")\n",
        "    print(\"Por favor, descarga el archivo .bin pre-entrenado para español desde el sitio de FastText\")\n",
        "    print(\"y asegúrate de que la variable 'path_to_fasttext' tenga la ruta correcta.\")\n",
        "    fasttext_vectors = None\n",
        "except Exception as e:\n",
        "    print(f\"Ocurrió un error al cargar el modelo FastText: {e}\")\n",
        "    fasttext_vectors = None"
      ],
      "metadata": {
        "id": "LnkWSkrpmBT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1d3aef-1d9b-4e08-bb0a-5abefa68a045"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando vectores FastText (.bin)... (¡Esto puede tardar MUCHO tiempo y consumir RAM!)\n",
            "¡Vectores FastText cargados! Vocabulario (estimado): 985667 palabras. Dimensión: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_word2vec = '/content/drive/MyDrive/glove_fasttext/SBW-vectors-300-min5.bin.gz' # La ruta del martes\n",
        "word2vec_vectors = None"
      ],
      "metadata": {
        "id": "KjLgGPmOmN8N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    print(\"\\nRecargando vectores Word2Vec...\")\n",
        "    word2vec_vectors = KeyedVectors.load_word2vec_format(path_to_word2vec, binary=True)\n",
        "    print(\"Vectores Word2Vec recargados.\")\n",
        "except Exception as e:\n",
        "    print(f\"No se pudo recargar Word2Vec desde '{path_to_word2vec}': {e}\")"
      ],
      "metadata": {
        "id": "L9YzR49AmKAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3478dfe-b040-417a-e932-f01156a4e0bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recargando vectores Word2Vec del martes...\n",
            "Vectores Word2Vec recargados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Micro-Laboratorio (Ejercicio Práctico)\n",
        "\n",
        "**Consigna:** (Asumiendo que `fasttext_vectors` y `word2vec_vectors` están cargados)\n",
        "\n",
        "1.  **Comparación de Resultados:**\n",
        "    *   Elegir 3 palabras que **sí** estén en ambos vocabularios (ej: 'gato', 'correr', 'inteligencia').\n",
        "    *   Para cada palabra, obtener las 5 más similares usando `word2vec_vectors.most_similar()` y `fasttext_vectors.most_similar()`.\n",
        "    *   Comparar las listas de similares. ¿Son idénticas? ¿Muy parecidas? ¿Diferentes? ¿Cuál les parece \"mejor\" o más coherente? Anotar observaciones.\n",
        "\n",
        "2.  **Test OOV Exhaustivo:**\n",
        "    *   Crear una lista propia de 10 palabras OOV. Incluyan:\n",
        "        *   Errores tipográficos comunes (ej: \"hobmre\", \"qeu\", \"dicimbre\").\n",
        "        *   Diminutivos/Aumentativos (ej: \"perrito\", \"casita\", \"libraco\").\n",
        "        *   Formas verbales conjugadas (ej: \"habíamos comido\", \"cantasteis\").\n",
        "        *   Palabras inventadas pero plausibles (ej: \"tecnoestrés\", \"computofilia\").\n",
        "    *   Para **cada** palabra OOV de su lista:\n",
        "        *   Verificar si da `KeyError` en `word2vec_vectors`.\n",
        "        *   Obtener las 3 palabras más similares usando `fasttext_vectors`. Anotar los resultados. ¿Los similares que da FastText tienen algún sentido basado en las partes de la palabra OOV?\n",
        "\n",
        "3.  **Discusión:**\n",
        "    *   ¿En qué tipo de aplicación real (ej: un chatbot de atención al cliente, un sistema de recomendación de noticias, un corrector ortográfico) creen que la capacidad OOV de FastText marcaría una diferencia significativa respecto a usar Word2Vec? ¿Por qué?"
      ],
      "metadata": {
        "id": "6bPYX6xPmdU0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1b5a90c",
        "outputId": "25d3cd98-9444-45bc-d30f-7a9ee116ce88"
      },
      "source": [
        "if word2vec_vectors and fasttext_vectors:\n",
        "    print(\"--- Comparando palabras comunes en Word2Vec y FastText ---\")\n",
        "\n",
        "    # Palabras que esperamos estén en ambos vocabularios\n",
        "    common_words = [\"gato\", \"correr\", \"inteligencia\"]\n",
        "\n",
        "    for palabra in common_words:\n",
        "        print(f\"\\n--- Palabra: '{palabra}' ---\")\n",
        "\n",
        "        # Obtener similares con Word2Vec\n",
        "        try:\n",
        "            similares_w2v = word2vec_vectors.most_similar(palabra, topn=5)\n",
        "            print(f\"  Similares (Word2Vec): {similares_w2v}\")\n",
        "        except KeyError:\n",
        "            print(f\"  Word2Vec: '{palabra}' no encontrada en el vocabulario.\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ERROR inesperado con Word2Vec para '{palabra}': {e}\")\n",
        "\n",
        "        # Obtener similares con FastText\n",
        "        try:\n",
        "            similares_ft = fasttext_vectors.most_similar(palabra, topn=5)\n",
        "            print(f\"  Similares (FastText): {similares_ft}\")\n",
        "        except KeyError:\n",
        "             # This should not happen if the word is in the explicit vocab,\n",
        "             # but FastText can still generate a vector even if not explicit.\n",
        "             print(f\"  FastText: '{palabra}' not found (unexpected for common word).\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ERROR inesperado con FastText para '{palabra}': {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nAmbos modelos (Word2Vec y FastText) deben estar cargados para realizar la comparación.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Comparando palabras comunes en Word2Vec y FastText ---\n",
            "\n",
            "--- Palabra: 'gato' ---\n",
            "  Similares (Word2Vec): [('perro', 0.8182171583175659), ('zorro', 0.7960419654846191), ('oso', 0.7677274346351624), ('conejo', 0.7547112703323364), ('mono', 0.7344450950622559)]\n",
            "  Similares (FastText): [('gatos', 0.6868153214454651), ('conejo', 0.6618362665176392), ('perro', 0.6526236534118652), ('gatito', 0.6358351111412048), ('zorro', 0.6104276776313782)]\n",
            "\n",
            "--- Palabra: 'correr' ---\n",
            "  Similares (Word2Vec): [('corriendo', 0.6818697452545166), ('andar', 0.6599047183990479), ('saltar', 0.6438890099525452), ('caminar', 0.6328942179679871), ('corría', 0.5944115519523621)]\n",
            "  Similares (FastText): [('correrse', 0.7749728560447693), ('corriendo', 0.7173823714256287), ('correrlo', 0.7168956398963928), ('correrla', 0.7070920467376709), ('correrlos', 0.6823992729187012)]\n",
            "\n",
            "--- Palabra: 'inteligencia' ---\n",
            "  Similares (Word2Vec): [('Inteligencia', 0.6916242837905884), ('contrainteligencia', 0.6242276430130005), ('HUMINT', 0.5998402833938599), ('contra-inteligencia', 0.5812575221061707), ('intelecto', 0.5662493109703064)]\n",
            "  Similares (FastText): [('‘inteligencia', 0.9258114099502563), ('la\\xa0inteligencia', 0.8669288158416748), ('inteligencia»', 0.8597841858863831), ('inteligencias', 0.8565053939819336), ('desinteligencia', 0.8338331580162048)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf2e929b",
        "outputId": "43c05764-b3fb-44fe-bd61-c5e79a879bd5"
      },
      "source": [
        "if word2vec_vectors and fasttext_vectors:\n",
        "    print(\"\\n--- Test OOV Exhaustivo ---\")\n",
        "\n",
        "    # Crear una lista propia de 10 palabras OOV\n",
        "    my_oov_words = [\n",
        "        \"hobmre\",         # Error tipográfico\n",
        "        \"qeu\",            # Error tipográfico\n",
        "        \"dicimbre\",       # Error tipográfico\n",
        "        \"perrito\",        # Diminutivo\n",
        "        \"casota\",         # Aumentativo (changed from casita to casota for variety)\n",
        "        \"libraco\",        # Aumentativo\n",
        "        \"habíamoscomido\", # Forma verbal conjugada (as one word)\n",
        "        \"cantasteis\",     # Forma verbal conjugada\n",
        "        \"tecnoestrés\",    # Palabra inventada/compuesta\n",
        "        \"computofilia\"    # Palabra inventada\n",
        "    ]\n",
        "\n",
        "    for palabra in my_oov_words:\n",
        "        print(f\"\\n--- Palabra OOV: '{palabra}' ---\")\n",
        "\n",
        "        # Intentar con Word2Vec\n",
        "        print(\"  Intentando con Word2Vec:\")\n",
        "        try:\n",
        "            vector_w2v = word2vec_vectors[palabra]\n",
        "            similares_w2v = word2vec_vectors.most_similar(palabra, topn=3)\n",
        "            print(f\"    ¡Encontrada! Vector: {vector_w2v.shape}, Similares: {similares_w2v}\")\n",
        "        except KeyError:\n",
        "            print(\"    ERROR: Palabra no encontrada en el vocabulario Word2Vec (KeyError).\")\n",
        "        except Exception as e:\n",
        "            print(f\"    ERROR inesperado con Word2Vec: {e}\")\n",
        "\n",
        "        # Intentar con FastText\n",
        "        print(\"  Intentando con FastText:\")\n",
        "        try:\n",
        "            vector_ft = fasttext_vectors[palabra]\n",
        "            similares_ft = fasttext_vectors.most_similar(palabra, topn=3)\n",
        "            print(f\"    ¡Vector generado! Vector: {vector_ft.shape}, Similares: {similares_ft}\")\n",
        "        except Exception as e:\n",
        "            # No debería fallar por KeyError con un modelo .bin, pero podría haber otro error\n",
        "            print(f\"    ERROR inesperado con FastText: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nAmbos modelos (Word2Vec y FastText) deben estar cargados para realizar el test OOV.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Test OOV Exhaustivo ---\n",
            "\n",
            "--- Palabra OOV: 'hobmre' ---\n",
            "  Intentando con Word2Vec:\n",
            "    ERROR: Palabra no encontrada en el vocabulario Word2Vec (KeyError).\n",
            "  Intentando con FastText:\n",
            "    ¡Vector generado! Vector: (300,), Similares: [('nobmre', 0.6312950253486633), ('ademre', 0.5202481746673584), ('demre', 0.5149299502372742)]\n",
            "\n",
            "--- Palabra OOV: 'qeu' ---\n",
            "  Intentando con Word2Vec:\n",
            "    ¡Encontrada! Vector: (300,), Similares: [('D-Mo', 0.6143811345100403), ('entenderias', 0.6070886850357056), ('encontrarias', 0.5987488031387329)]\n",
            "  Intentando con FastText:\n",
            "    ¡Vector generado! Vector: (300,), Similares: [('qeuab', 0.6885186433792114), ('qeuad', 0.6670765280723572), ('wikisilki/pi', 0.6110560297966003)]\n",
            "\n",
            "--- Palabra OOV: 'dicimbre' ---\n",
            "  Intentando con Word2Vec:\n",
            "    ¡Encontrada! Vector: (300,), Similares: [('Septiempre', 0.8246644139289856), ('Super_Jr._Tag_Tournament', 0.8202389478683472), ('noviebre', 0.8184508085250854)]\n",
            "  Intentando con FastText:\n",
            "    ¡Vector generado! Vector: (300,), Similares: [('cimbres', 0.6492888331413269), ('cimbro', 0.6209564805030823), ('cimbros', 0.5852233171463013)]\n",
            "\n",
            "--- Palabra OOV: 'perrito' ---\n",
            "  Intentando con Word2Vec:\n",
            "    ¡Encontrada! Vector: (300,), Similares: [('perro', 0.7127845883369446), ('gatito', 0.6983193755149841), ('cachorro', 0.6888414025306702)]\n",
            "  Intentando con FastText:\n",
            "    ¡Vector generado! Vector: (300,), Similares: [('perritos', 0.82405024766922), ('perrita', 0.7756099700927734), ('perritas', 0.7066512107849121)]\n",
            "\n",
            "--- Palabra OOV: 'casota' ---\n",
            "  Intentando con Word2Vec:\n",
            "    ¡Encontrada! Vector: (300,), Similares: [('Escupidera', 0.7997499704360962), ('tontísima', 0.7902153134346008), ('Sorty', 0.7882706522941589)]\n",
            "  Intentando con FastText:\n",
            "    ¡Vector generado! Vector: (300,), Similares: [('asota', 0.7972043752670288), ('kasota', 0.784034252166748), ('navasota', 0.7629576921463013)]\n",
            "\n",
            "--- Palabra OOV: 'libraco' ---\n",
            "  Intentando con Word2Vec:\n",
            "    ¡Encontrada! Vector: (300,), Similares: [('malva-rosa', 0.7977491617202759), ('sobrinillo', 0.7970112562179565), ('atufado', 0.7937419414520264)]\n",
            "  Intentando con FastText:\n",
            "    ¡Vector generado! Vector: (300,), Similares: [('libracos', 0.851459801197052), ('libración', 0.672081470489502), ('libraciones', 0.6215488314628601)]\n",
            "\n",
            "--- Palabra OOV: 'habíamoscomido' ---\n",
            "  Intentando con Word2Vec:\n",
            "    ERROR: Palabra no encontrada en el vocabulario Word2Vec (KeyError).\n",
            "  Intentando con FastText:\n",
            "    ¡Vector generado! Vector: (300,), Similares: [('habíamos', 0.694095253944397), ('comido', 0.6214999556541443), ('omido', 0.5806320309638977)]\n",
            "\n",
            "--- Palabra OOV: 'cantasteis' ---\n",
            "  Intentando con Word2Vec:\n",
            "    ERROR: Palabra no encontrada en el vocabulario Word2Vec (KeyError).\n",
            "  Intentando con FastText:\n",
            "    ¡Vector generado! Vector: (300,), Similares: [('cantaste', 0.8618875741958618), ('fuisteis', 0.7056925296783447), ('gusteis', 0.7031436562538147)]\n",
            "\n",
            "--- Palabra OOV: 'tecnoestrés' ---\n",
            "  Intentando con Word2Vec:\n",
            "    ERROR: Palabra no encontrada en el vocabulario Word2Vec (KeyError).\n",
            "  Intentando con FastText:\n",
            "    ¡Vector generado! Vector: (300,), Similares: [('tecnoestructura', 0.8233116269111633), ('xenoestrógeno', 0.7390566468238831), ('xenoestrógenos', 0.7244404554367065)]\n",
            "\n",
            "--- Palabra OOV: 'computofilia' ---\n",
            "  Intentando con Word2Vec:\n",
            "    ERROR: Palabra no encontrada en el vocabulario Word2Vec (KeyError).\n",
            "  Intentando con FastText:\n",
            "    ¡Vector generado! Vector: (300,), Similares: [('sitofilia', 0.7233273386955261), ('textofilia', 0.7167273759841919), ('gerontofilia', 0.7099736928939819)]\n"
          ]
        }
      ]
    }
  ]
}